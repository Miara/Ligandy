{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projekt: Machine Learning <br>\n",
    "Student: Wojciech Miarczyński 106532 <br>\n",
    "Data   : 06-02-2016 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W projekcie korzystałem z 2 klasyfikatorów : AdaBoostClassifier oraz BaggingClassifier. Próbowałem również dobrać różne parametry do drzewa decyzyjnego i searchGridu. Ostatecznie okazało się że BaggingClassifier był najbardziej skuteczny, ponieważ zwracał wynik 73%. AdaBoostClassifier za to zwracał co najwyżej 55%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystane biblioteki :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm, grid_search, tree\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.externals import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcje do wczytywania i filtrowania danych : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file, sep):\n",
    "    df = pd.read_csv(file,sep=sep, header=0, na_values=[\"nan\", \"NA\", \"NaN\"], keep_default_na = False)\n",
    "    print \"data read: \",format(len(df)),\",\",len(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_data(data,remove_classes):\n",
    "    #Filtrowanie kolumn\n",
    "    filtered = data[~data[\"res_name\"].isin(remove_classes)]\n",
    "\n",
    "    #Unikalnosc pdb_code , res_name\n",
    "    unique = filtered.drop_duplicates(subset=[\"pdb_code\", \"res_name\"], keep='first')\n",
    "\n",
    "    #Ograniczenie do 5 powtorzen\n",
    "    counts = unique[['res_name']].stack().value_counts()\n",
    "    values = counts[counts>=5].index\n",
    "    min5Occurs = unique.loc[unique['res_name'].isin(values)]\n",
    "\n",
    "    print \"original: \",format(len(data)),\",\",len(data.columns)\n",
    "    print \"filtered: \",format(len(filtered)),\",\",len(filtered.columns)\n",
    "    print \"unique: \",format(len(unique)),\",\",len(unique.columns)\n",
    "    print \"5+ occurs: \",format(len(min5Occurs)),\",\",len(min5Occurs.columns)\n",
    "\n",
    "    return min5Occurs\n",
    "\n",
    "\n",
    "def remove_na_columns(df):\n",
    "    no_na_columns = df.count()==len(df)\n",
    "    no_na_columns = no_na_columns.values\n",
    "    return df.iloc[:,no_na_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja do uczenia :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data,test_data):\n",
    "    #zamiana reprezentacji tekstowej na binarna\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(data[['res_name']])\n",
    "    data[['res_name']] = encoder.transform(data[['res_name']])\n",
    "\n",
    "    #usuniecie kolumn ktore zawieraja NA\n",
    "    data = remove_na_columns(data)\n",
    "    test_data = remove_na_columns(test_data)\n",
    "\n",
    "    ##zmienna tymczasowa, potrzebna pozniej przy klasyfikacji\n",
    "    original = data\n",
    "\n",
    "    ##selekcja kolumn ktore sa typu float (\n",
    "    float_idx = data.dtypes == np.float64\n",
    "    data = data.loc[:,float_idx]\n",
    "\n",
    "    test_float_idx = test_data.dtypes == np.float64\n",
    "    test_data = test_data.loc[:,test_float_idx]\n",
    "\n",
    "    ##selekcja kolumn ktore sa wspolne dla test_data i data\n",
    "    common_columns = [col for col in test_data if col in data]\n",
    "    test_data = test_data[common_columns]\n",
    "    data = data[common_columns]\n",
    "\n",
    "    ##klasyfikacja\n",
    "    df, classes = data.loc[:,float_idx], original[['res_name']]\n",
    "\n",
    "    my_tree = tree.DecisionTreeClassifier(max_features = \"auto\",max_depth = None)\n",
    "    #method = AdaBoostClassifier(base_estimator = my_tree)\n",
    "    method = BaggingClassifier(base_estimator = my_tree)\n",
    "\n",
    "    params = {\n",
    "        \"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "        \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "        \"n_estimators\": [1, 5]\n",
    "     }\n",
    "\n",
    "    classificator = grid_search.GridSearchCV(method, param_grid=params, scoring = 'recall')\n",
    "    classificator.fit(df, np.asarray(classes).ravel())\n",
    "\n",
    "    joblib.dump(classificator, \"klasyfikator.pk\")\n",
    "\n",
    "    print 'grid_scores:', classificator.grid_scores_\n",
    "    print 'best_estimator:', classificator.best_estimator_\n",
    "    print 'best_score:', classificator.best_score_\n",
    "    print 'best_params:', classificator.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja main - wczytanie danych :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read:  40309 , 795\ndata read: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18917 , 824\noriginal: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40309 , 795\nfiltered:  40027 , 795\nunique:  14132 , 795\n5+ occurs:  10767 , 795\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "LABELS = True\n",
    "\n",
    "#Wczytanie danych\n",
    "data = read(\"all_summary.txt\",\";\")\n",
    "test_data = read(\"test_data.txt\",\",\")\n",
    "\n",
    "#filtrowanie danych\n",
    "data = filter_data(data,[\"DA\",\"DC\",\"DT\",\"DU\",\"DG\", \"DI\",\"UNK\",\"UNX\",\"UNL\",\"PR\",\"PD\",\"Y1\",\"EU\",\"N\",\"15P\",\"UQ\",\"PX4\", \"NAN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja main - uczenie na normalnym zbiorze :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_scores: [mean: 0.16681, std: 0.00460, params: {'n_estimators': 1, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'best'}, mean: 0.23191, std: 0.00931, params: {'n_estimators': 5, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'best'}, mean: 0.15139, std: 0.00188, params: {'n_estimators': 1, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'random'}, mean: 0.21259, std: 0.01271, params: {'n_estimators': 5, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'random'}, mean: 0.16476, std: 0.00388, params: {'n_estimators': 1, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best'}, mean: 0.22513, std: 0.00427, params: {'n_estimators': 5, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best'}, mean: 0.14888, std: 0.00347, params: {'n_estimators': 1, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'random'}, mean: 0.20061, std: 0.00722, params: {'n_estimators': 5, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'random'}]\nbest_estimator: BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best'),\n         bootstrap=True, bootstrap_features=False, max_features=1.0,\n         max_samples=1.0, n_estimators=5, n_jobs=1, oob_score=False,\n         random_state=None, verbose=0, warm_start=False)\nbest_score: 0.231912324696\nbest_params: {'n_estimators': 5, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "learn(data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja main - Uczenie na zbiorze etykiet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read:  11005 , 2\ngrid_scores:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [mean: 0.52206, std: 0.01177, params: {'n_estimators': 1, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'best'}, mean: 0.72295, std: 0.00969, params: {'n_estimators': 5, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'best'}, mean: 0.52540, std: 0.00877, params: {'n_estimators': 1, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'random'}, mean: 0.72639, std: 0.00732, params: {'n_estimators': 5, 'base_estimator__criterion': 'gini', 'base_estimator__splitter': 'random'}, mean: 0.54537, std: 0.00892, params: {'n_estimators': 1, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best'}, mean: 0.73270, std: 0.00861, params: {'n_estimators': 5, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best'}, mean: 0.51556, std: 0.00338, params: {'n_estimators': 1, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'random'}, mean: 0.72852, std: 0.01143, params: {'n_estimators': 5, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'random'}]\nbest_estimator: BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n            max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best'),\n         bootstrap=True, bootstrap_features=False, max_features=1.0,\n         max_samples=1.0, n_estimators=5, n_jobs=1, oob_score=False,\n         random_state=None, verbose=0, warm_start=False)\nbest_score: 0.732701773939\nbest_params: {'n_estimators': 5, 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "if(LABELS):\n",
    "    labels = read(\"labels.txt\",\",\")\n",
    "    data['res_name']=labels['res_name_group']\n",
    "    \n",
    "#uczenie\n",
    "learn(data,test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}